## Обучение модели классификации комментариев

### Задача проекта
Обучение модели классификации комментариев

### Описание проекта
Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Требуется инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

### Ключевые слова проекта
МО для текстов

### Выводы
Bert-toxic, предсказывает токсичность комментариев по мультиклассу ('toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate') и, как несложно заметить, 'toxic' и 'severe_toxic' имеют высокие веса, в то время как другие типы "недоброжелательного поведения" имеют гораздо более скромные по модулю коэффициены. Как мы можем заметить, мульклассовые f1 метрики на тестовой выборке демонстрируют крайне высокое значение параметров (> 0.90). Целевое значение метрики f1 в 0.75 также достигнуто.
